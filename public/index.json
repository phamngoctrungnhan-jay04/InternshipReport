[
{
	"uri": "http://localhost:1313/InternshipReport/4-eventparticipated/4.2-event2/",
	"title": "Event 2",
	"tags": [],
	"description": "",
	"content": "Summary Report: ‚ÄúAWS Well-Architected Security Pillar‚Äù Event Objectives Deep dive into the 5 core pillars of AWS Security: IAM, Detection, Infrastructure Protection, Data Protection, and Incident Response. Understand modern security principles: Zero Trust, Least Privilege, and Defense in Depth. Learn to automate security checks and incident response using AWS native tools. Identify common cloud threats in the Vietnam market and how to mitigate them. Key Highlights Opening \u0026amp; Security Foundation [Image of AWS Shared Responsibility Model] Core Principles: Moving beyond perimeter security to Defense in Depth, Zero Trust architecture, and strictly enforcing Least Privilege. Shared Responsibility Model: Clarifying what AWS secures (of the cloud) vs. what the customer secures (in the cloud). Local Context: Discussing top security threats specifically targeting cloud environments in Vietnam. Pillar 1: Identity \u0026amp; Access Management (IAM) [Image of IAM Identity Center architecture] Modern IAM Architecture: Moving away from long-term credentials (IAM Users) to temporary credentials (IAM Roles). Governance: Using IAM Identity Center for SSO and centralized management. Control: Implementing SCPs (Service Control Policies) and permission boundaries for multi-account environments. Best Practices: Enforcing MFA, regular credential rotation, and using Access Analyzer to validate policies. Pillar 2: Detection \u0026amp; Continuous Monitoring Logging Strategy: \u0026ldquo;Log everything\u0026rdquo; approach using CloudTrail (org-level), VPC Flow Logs, and ALB/S3 logs. Threat Detection: Utilizing Amazon GuardDuty for intelligent threat detection. Centralization: Aggregating findings in AWS Security Hub. Detection-as-Code: Automating alerts using Amazon EventBridge to trigger immediate notifications. Pillar 3: Infrastructure Protection [Image of AWS Network Security architecture] Network Security: Implementing rigorous VPC segmentation and distinguishing strictly between private and public subnets. Firewalls: Understanding the layered defense using WAF (Web Application Firewall), AWS Shield (DDoS), and Network Firewall. Access Control: Differentiating between Stateful (Security Groups) and Stateless (NACLs) firewalls. Pillar 4: Data Protection Encryption Strategy: At-rest: Encrypting S3 buckets, EBS volumes, RDS, and DynamoDB. In-transit: TLS/SSL enforcement. Key Management: Managing keys via AWS KMS (Key Management Service), focusing on grants and rotation policies. Secrets Management: Removing hardcoded credentials from code by using Secrets Manager and Systems Manager Parameter Store. Pillar 5: Incident Response (IR) [Image of Automated Incident Response workflow] IR Lifecycle: Preparation -\u0026gt; Detection \u0026amp; Analysis -\u0026gt; Containment, Eradication \u0026amp; Recovery -\u0026gt; Post-Incident Activity. Automation: Using AWS Lambda and Step Functions to auto-remediate issues (e.g., isolating a compromised EC2 instance). Playbooks: Walkthrough of standard responses for scenarios like \u0026ldquo;Compromised IAM Key,\u0026rdquo; \u0026ldquo;S3 Public Exposure,\u0026rdquo; and \u0026ldquo;Malware Detection.\u0026rdquo; Key Takeaways Identity is the New Perimeter Identity management is the most critical line of defense. Long-term access keys are a major risk; utilizing IAM Roles and SSO is mandatory for a modern architecture. Visibility is Paramount You cannot protect what you cannot see. Enabling centralized logging (CloudTrail, Config) and threat detection (GuardDuty) is the first step in any security strategy. Automate Security Humans are slow; attacks are fast. Security responses (locking down a user, blocking an IP) should be automated via code (Lambda/EventBridge) wherever possible. Applying to Work Audit IAM Policies: Review current permissions to ensure \u0026ldquo;Least Privilege\u0026rdquo; and remove unused IAM Users. Enable GuardDuty: Activate GuardDuty in the main region to detect anomalies immediately. Encrypt Data: Ensure all new S3 buckets and EBS volumes have default encryption enabled via KMS. Develop IR Playbooks: Draft a basic Incident Response plan for \u0026ldquo;S3 Public Leak\u0026rdquo; and \u0026ldquo;Compromised Credentials\u0026rdquo; scenarios. Event Experience The \u0026ldquo;AWS Well-Architected Security Pillar\u0026rdquo; workshop was an intensive and highly focused morning session. It provided a structured approach to security that is often overlooked in rushed development cycles.\nDeep Dive into \u0026ldquo;Defense in Depth\u0026rdquo; The session on Infrastructure Protection clarified how to layer security controls (WAF -\u0026gt; NACL -\u0026gt; SG) so that if one fails, others are still in place. Practical Focus on Automation Seeing the \u0026ldquo;Mini Demo\u0026rdquo; on validating IAM policies and simulating access was very helpful. It showed that security can be tested just like software code. The Incident Response segment changed my perspective: instead of waking up at 3 AM to fix a hack manually, we can write Lambda functions to contain threats automatically. Local Context Hearing about common pitfalls in Vietnamese enterprises helped me relate the theoretical concepts to the actual risks our business faces daily. Some event photos Add your event photos here\nOverall, this event reinforced that security is not just a \u0026ldquo;gatekeeper\u0026rdquo; but an enabler of speed when done correctly through automation and solid architecture.\n"
},
{
	"uri": "http://localhost:1313/InternshipReport/4-eventparticipated/4.1-event1/",
	"title": "Event 1",
	"tags": [],
	"description": "",
	"content": "Summary Report: ‚ÄúDevOps on AWS‚Äù Event Objectives Understand the DevOps mindset, culture, and key performance metrics (DORA). Master the AWS CI/CD toolchain for automated software delivery. Learn Infrastructure as Code (IaC) principles using CloudFormation and CDK. Explore containerization strategies and observability best practices on AWS. Key Highlights DevOps Culture and Key Metrics Mindset Shift: Moving away from silos to shared responsibility between Development and Operations. Key Metrics (DORA): Focusing on Deployment Frequency, Lead Time for Changes, Mean Time to Restore (MTTR), and Change Failure Rate to measure success. Benefits: Faster innovation, higher reliability, and improved collaboration. AWS DevOps Services ‚Äì CI/CD Pipeline [Image of AWS CI/CD pipeline architecture] We explored the full automation pipeline, moving from manual deployments to orchestration:\nSource Control: Utilizing AWS CodeCommit and implementing Git strategies like GitFlow and Trunk-based development. Build \u0026amp; Test: Using AWS CodeBuild for compiling source code, running tests, and producing software packages. Deployment Strategies: implementing AWS CodeDeploy for Blue/Green, Canary, and Rolling updates to minimize downtime. Orchestration: Tying it all together with AWS CodePipeline. Infrastructure as Code (IaC) [Image of AWS CloudFormation workflow] Transitioning from manual console clicks to code-defined infrastructure:\nAWS CloudFormation: Using JSON/YAML templates to define resources, manage stacks, and detect infrastructure drift. AWS CDK (Cloud Development Kit): Defining cloud resources using familiar programming languages (Python, TypeScript, Java) to create reusable constructs. Tool Selection: Discussing when to use declarative templates (CloudFormation) vs. imperative code (CDK). Container Services on AWS [Image of Docker container architecture] Docker Fundamentals: Packaging applications into lightweight, portable containers. Registry: Using Amazon ECR for secure image storage and vulnerability scanning. Orchestration: Comparing Amazon ECS ( "
},
{
	"uri": "http://localhost:1313/InternshipReport/3-blogstranslated/3.1-blog1/",
	"title": "Blog 1",
	"tags": [],
	"description": "",
	"content": "How BeyondTrust embedded Amazon QuickSight for identity security insights English (Original) üåê Read Original Blog Vietnamese (Translation) üáªüá≥ Read Vietnamese Translation "
},
{
	"uri": "http://localhost:1313/InternshipReport/3-blogstranslated/3.2-blog2/",
	"title": "Blog 2",
	"tags": [],
	"description": "",
	"content": "How to securely deliver business intelligence to internal-facing applications with Amazon QuickSight English (Original) üåê Read Original Blog Vietnamese (Translation) üáªüá≥ Read Vietnamese Translation "
},
{
	"uri": "http://localhost:1313/InternshipReport/3-blogstranslated/3.3-blog3/",
	"title": "Blog 3",
	"tags": [],
	"description": "",
	"content": "Software developer career paths: 2025 job guide English (Original) üåê Read Original Blog Vietnamese (Translation) üáªüá≥ Read Vietnamese Translation "
},
{
	"uri": "http://localhost:1313/InternshipReport/5-workshop/5.4-databaseandstorage/5.4.1-create-rds/",
	"title": "Create RDS",
	"tags": [],
	"description": "",
	"content": " Open the Amazon Aurora and RDS\nIn left navbar, choose Databases, then click Create database In create console, choose Full configuration\nThen choose database type is MySQL\nChoose Templates is Production Select Availability and durability is Multi-AZ DB cluster deployment (3 instances)\nFill DB instance identifier\nChoose Self managed\nSpacific Master password In Instance configuration, choose db.m5d.large\nIn Storage, Allocated storage fill in 100 and Provisioned IOPS is 1000\nIn Connectivity, choose Don\u0026rsquo;t connect to an EC2, then select VPC Choose DB subnet group and then in VPC security group (firewall) select Choose existing\nSelect rds-sg\nThen click Create database "
},
{
	"uri": "http://localhost:1313/InternshipReport/5-workshop/5.3-vpc/5.3.1-create-route-table/",
	"title": "Create Route table and Internet Gateway",
	"tags": [],
	"description": "",
	"content": " A Route Table is a set of rules (routes) used by a router to determine the best path for data packets to reach their destination.\nOpen the Amazon VPC console Choose Route tables, then click Create route table In the Create route table console: Specify name of Route table Choose VPC created Then click Create route table In Route table console, click Route table created Choose Route in navbar -\u0026gt; click Edit routes Edit routes console -\u0026gt; choose Target local -\u0026gt; Save changes Choose Internet Gateway in left navbar -\u0026gt; click Create internet gateway In Create Internet Gateway Specify name of Internet Gateway Click Create internet gateway Back to Route table -\u0026gt; Create route table like step 3 Click this Route table -\u0026gt; Edit routes In Target choose Internet Gateway created Then click **Save changes "
},
{
	"uri": "http://localhost:1313/InternshipReport/4-eventparticipated/4.3-event3/",
	"title": "Event 3",
	"tags": [],
	"description": "",
	"content": "Summary Report: ‚ÄúGenAI-powered App-DB Modernization workshop‚Äù Event Objectives Share best practices in modern application design Introduce Domain-Driven Design (DDD) and event-driven architecture Provide guidance on selecting the right compute services Present AI tools to support the development lifecycle Speakers Jignesh Shah ‚Äì Director, Open Source Databases Erica Liu ‚Äì Sr. GTM Specialist, AppMod Fabrianne Effendi ‚Äì Assc. Specialist SA, Serverless Amazon Web Services Key Highlights Identifying the drawbacks of legacy application architecture Long product release cycles ‚Üí Lost revenue/missed opportunities Inefficient operations ‚Üí Reduced productivity, higher costs Non-compliance with security regulations ‚Üí Security breaches, loss of reputation Transitioning to modern application architecture ‚Äì Microservices Migrating to a modular system ‚Äî each function is an independent service communicating via events, built on three core pillars:\nQueue Management: Handle asynchronous tasks Caching Strategy: Optimize performance Message Handling: Flexible inter-service communication Domain-Driven Design (DDD) Four-step method: Identify domain events ‚Üí arrange timeline ‚Üí identify actors ‚Üí define bounded contexts Bookstore case study: Demonstrates real-world DDD application Context mapping: 7 patterns for integrating bounded contexts Event-Driven Architecture 3 integration patterns: Publish/Subscribe, Point-to-point, Streaming Benefits: Loose coupling, scalability, resilience Sync vs async comparison: Understanding the trade-offs Compute Evolution Shared Responsibility Model: EC2 ‚Üí ECS ‚Üí Fargate ‚Üí Lambda Serverless benefits: No server management, auto-scaling, pay-for-value Functions vs Containers: Criteria for appropriate choice Amazon Q Developer SDLC automation: From planning to maintenance Code transformation: Java upgrade, .NET modernization AWS Transform agents: VMware, Mainframe, .NET migration Key Takeaways Design Mindset Business-first approach: Always start from the business domain, not the technology Ubiquitous language: Importance of a shared vocabulary between business and tech teams Bounded contexts: Identifying and managing complexity in large systems Technical Architecture Event storming technique: Practical method for modeling business processes Use event-driven communication instead of synchronous calls Integration patterns: When to use sync, async, pub/sub, streaming Compute spectrum: Criteria for choosing between VM, containers, and serverless Modernization Strategy Phased approach: No rushing ‚Äî follow a clear roadmap 7Rs framework: Multiple modernization paths depending on the application ROI measurement: Cost reduction + business agility Applying to Work Apply DDD to current projects: Event storming sessions with business teams Refactor microservices: Use bounded contexts to define service boundaries Implement event-driven patterns: Replace some sync calls with async messaging Adopt serverless: Pilot AWS Lambda for suitable use cases Try Amazon Q Developer: Integrate into the dev workflow to boost productivity Event Experience Attending the ‚ÄúGenAI-powered App-DB Modernization‚Äù workshop was extremely valuable, giving me a comprehensive view of modernizing applications and databases using advanced methods and tools. Key experiences included:\nLearning from highly skilled speakers Experts from AWS and major tech organizations shared best practices in modern application design. Through real-world case studies, I gained a deeper understanding of applying DDD and Event-Driven Architecture to large projects. Hands-on technical exposure Participating in event storming sessions helped me visualize how to model business processes into domain events. Learned how to split microservices and define bounded contexts to manage large-system complexity. Understood trade-offs between synchronous and asynchronous communication and integration patterns like pub/sub, point-to-point, streaming. Leveraging modern tools Explored Amazon Q Developer, an AI tool for SDLC support from planning to maintenance. Learned to automate code transformation and pilot serverless with AWS Lambda to improve productivity. Networking and discussions The workshop offered opportunities to exchange ideas with experts, peers, and business teams, enhancing the ubiquitous language between business and tech. Real-world examples reinforced the importance of the business-first approach rather than focusing solely on technology. Lessons learned Applying DDD and event-driven patterns reduces coupling while improving scalability and resilience. Modernization requires a phased approach with ROI measurement; rushing the process can be risky. AI tools like Amazon Q Developer can significantly boost productivity when integrated into the current workflow. Some event photos Add your event photos here\nOverall, the event not only provided technical knowledge but also helped me reshape my thinking about application design, system modernization, and cross-team collaboration.\n"
},
{
	"uri": "http://localhost:1313/InternshipReport/",
	"title": "Internship Report",
	"tags": [],
	"description": "",
	"content": "Internship Report Student Information: Full Name: Ph·∫°m Ng·ªçc Trung Nh√¢n\nPhone Number: 0364369496\nEmail: nhanpntde180196@fpt.edu.vn\nUniversity: FPT University HCM Campus\nMajor: Information Technology\nClass: AWS\nInternship Company: Amazon Web Services Vietnam Co., Ltd.\nInternship Position: FCJ Cloud Intern\nInternship Duration: From 08/09/2025 to 14/12/2025\nReport Content Worklog Proposal Translated Blogs Events Participated Workshop Self-evaluation Sharing and Feedback "
},
{
	"uri": "http://localhost:1313/InternshipReport/5-workshop/5.1-workshop-overview/",
	"title": "Introduction",
	"tags": [],
	"description": "",
	"content": "ApexEV ‚Äî Workshop Introduction (Short) ApexEV is an enterprise-grade EV garage management platform that digitizes workshop operations, improves customer experience, and helps technicians work faster and safer.\nWhy this workshop:\nSolve common garage problems: manual processes, poor transparency, weak customer care, and data risk. Build a secure, scalable and cost-efficient cloud backend from day one using AWS best practices. Core architecture (summary):\nFrontend: React app hosted on AWS Amplify (CI/CD + CloudFront). Backend: Spring Boot services in ECS (Fargate) ‚Äî serverless containers. Database: Amazon RDS (private subnets, automated backups, KMS encryption). Storage: Amazon S3 for media (use presigned URLs for direct uploads). API + Async: API Gateway as HTTPS ingress; SNS ‚Üí Lambda ‚Üí SES for email; Lambda ‚Üí Bedrock for AI/chat. Network \u0026amp; Security: VPC (public/private), Security Groups, VPC Endpoints, WAF and least-privilege IAM. Key benefits:\nSecurity-first: backend and DB remain private; edge services terminate TLS and enforce WAF/rate limits. Cost-aware: Fargate + Lambda (pay-per-use), lifecycle rules and autoscaling reduce costs. Modern \u0026amp; modular: frontend/backend separation, event-driven async flows for resilience and scale. Workshop goals:\nProvision network and secure services, deploy frontend + backend, connect RDS and S3, and integrate email and AI pipelines. Each module includes steps, recommended settings and cleanup instructions. "
},
{
	"uri": "http://localhost:1313/InternshipReport/1-worklog/1.1-week1/",
	"title": "Week 1 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 1 Objectives: Integrate into the AWS work culture and get to know new colleagues during the OJT process at First Cloud Journey (FCJ). Understand foundational knowledge of AWS Core Services. Practice operations on the AWS Management Console. Tasks carried out this week: Day Task Start Date Completion Date Reference Material Mon - Conducted preparatory research on AWS - Reviewed internship policies and working procedures at the FCJ unit 09/08/2025 09/08/2025 Tue - Studied Module 1: AWS infrastructure fundamentals and management tools + Overview of AWS global architecture + Management and cost-optimization principles Practice: Created and verified an AWS account 09/09/2025 09/09/2025 https://cloudjourney.awsstudygroup.com/ https://www.youtube.com/watch?v=HxYZAK1coOI https://www.youtube.com/watch?v=IK59Zdd1poE https://www.youtube.com/watch?v=HSzrWGqo3ME https://www.youtube.com/watch?v=pjr5a-HYAjI https://www.youtube.com/watch?v=2PQYqH_HkXw https://www.youtube.com/watch?v=IY61YlmXQe8 https://www.youtube.com/watch?v=Hku7exDBURo Wed - Explored the AWS Management Console and the AWS CLI - Practice: + Hands-on navigation of the Console + Configured MFA and IAM basics + Installed and configured the AWS CLI 09/10/2025 09/10/2025 https://cloudjourney.awsstudygroup.com/ Thu - Studied Amazon EC2 fundamentals: + Instance types and sizing + Storage options: EBS vs. Instance Store + Network \u0026amp; security concepts: Security Groups, Key Pairs, Public/Private/Elastic IPs + IAM Roles and SSH access procedures 09/11/2025 09/11/2025 https://cloudjourney.awsstudygroup.com/ Fri - Practice: + Launched an EC2 instance and validated connectivity + Connected to the instance via SSH for verification 09/12/2025 09/12/2025 https://cloudjourney.awsstudygroup.com/ Week 1 Achievements: Became acquainted with the FCJ internship rules and working procedures.\nGained a clear overview of AWS global infrastructure, management tooling, and cost-optimization concepts covered in Module 1.\nCreated and verified an AWS Free Tier account.\nConfigured account security on the AWS Console:\nEnabled MFA (Multi-Factor Authentication). Created and managed basic IAM users and groups. Installed and configured the AWS CLI on a local workstation.\nConsolidated core Amazon EC2 knowledge, including:\nInstance types and sizing considerations. Storage alternatives (EBS vs. Instance Store). Network and security primitives: Security Groups, Key Pairs, and IP addressing distinctions. The purpose and usage of IAM Roles for delegated permissions. Performed hands-on EC2 exercises:\nLaunched an EC2 instance and verified operation. Connected to the instance using SSH and executed basic interactions. "
},
{
	"uri": "http://localhost:1313/InternshipReport/1-worklog/1.2-week2/",
	"title": "Week 2 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 2 Objectives: Deeply understand AWS networking architecture: VPC, security features, and Multi-VPC models. Master advanced networking concepts: VPN, DirectConnect, and LoadBalancer. Practice building a complete network system: Subnet, Route Table, Internet Gateway, Security Group, and Network ACLs. Connect and establish teamwork with final project team members. Tasks executed this week: Day Task Start Date End Date Resources Mon - Reviewed AWS Virtual Private Cloud (VPC) concepts - Examined VPC security capabilities and multi-VPC design patterns 15/09/2025 15/09/2025 https://www.youtube.com/watch?v=O9Ac_vGHquM https://www.youtube.com/watch?v=BPuD1l2hEQ4\u0026t Tue - Studied VPN, AWS Direct Connect, and Load Balancing mechanisms; collected supplementary resources 16/09/2025 16/09/2025 https://www.youtube.com/watch?v=CXU8D3kyxIc\u0026t Wed - Practice: + Explored VPC configuration + Created subnets + Configured route tables and Internet Gateway 17/09/2025 17/09/2025 https://www.youtube.com/watch?v=dHoYmQR7FYs https://www.youtube.com/watch?v=XBJgHS3XQjk Thu - Practiced configuring Security Groups and Network ACLs - Explored the VPC Resource Map utility for visualizing resources 18/09/2025 18/09/2025 https://www.youtube.com/watch?v=B1qxOQLmavQ https://www.youtube.com/watch?v=GVDsDu9dOFY\u0026t https://www.youtube.com/watch?v=fZa_kQ69stI Fri - Reviewed weekly findings and deepened VPC understanding - Attended initial meeting with the final project team to align goals 19/09/2025 19/09/2025 https://cloudjourney.awsstudygroup.com/ Week 2 Achievements: Developed a clear understanding of key Amazon VPC elements:\nCIDR notation and subnetting Public vs. Private subnets Route tables and Internet Gateways (IGW) Acquired knowledge of connectivity and load distribution options:\nVPN and AWS Direct Connect for hybrid connectivity Load balancer fundamentals for traffic distribution Implemented network security constructs:\nConfigured Security Groups (instance-level, stateful) Configured Network ACLs (subnet-level, stateless) Utilized the VPC Resource Map to visualize network topology and data flow.\nHeld the kickoff meeting with the project team to coordinate next steps.\n"
},
{
	"uri": "http://localhost:1313/InternshipReport/1-worklog/1.3-week3/",
	"title": "Week 3 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 3 Objectives: Master EC2 compute services: Lifecycle, Storage (EBS/Instance Store), and Auto Scaling. Implement advanced connectivity using AWS Transit Gateway. Deploy scalable storage and content delivery solutions (S3 \u0026amp; CloudFront). Explore foundational AI/ML concepts (NLP, Sentiment Analysis) for the final project. Collaborate with the team to brainstorm and finalize the final project idea. Tasks completed this week: Day Task Start Date End Date Resources Mon - Provisioned EC2 instances within subnets - Practiced creating Internet Gateways - Reviewed Transit Gateway route table concepts and connectivity - Verified EC2-to-endpoint connectivity 22/09/2025 22/09/2025 https://www.youtube.com/@AWSStudyGroup/ https://cloudjourney.awsstudygroup.com/ Tue - Conducted an in-depth study of EC2 features: AMIs, backups, key pairs, EBS, instance store, user-data/metadata, and Auto Scaling 23/09/2025 23/09/2025 https://cloudjourney.awsstudygroup.com/ https://www.youtube.com/@AWSStudyGroup/ Wed - Deployed infrastructure components - Established a backup plan and executed recovery tests - Cleaned up temporary resources - Created an S3 bucket for storage 24/09/2025 24/09/2025 https://cloudjourney.awsstudygroup.com/ https://www.youtube.com/@AWSStudyGroup/ Thu - Provisioned EC2 for Storage Gateway tasks - Deployed a simple static website - Configured S3 public access settings and object permissions - Experimented with AWS CloudFront configuration to accelerate content delivery 25/09/2025 25/09/2025 https://cloudjourney.awsstudygroup.com/ https://www.youtube.com/@AWSStudyGroup/ Fri - Introduced supervised ML techniques and sentiment analysis - Performed basic NLP preprocessing - Visualized tweet datasets and experimented with logistic regression models - Held a team brainstorming session to refine the final project concept 26/09/2025 26/09/2025 https://www.coursera.org/learn/classification-vector-spaces-in-nlp/ Week 3 Achievements: Managed and optimized EC2 instances, including AMI handling, key-pair setup, user-data, and storage configuration.\nDistinguished storage options (EBS vs. Instance Store) and implemented Auto Scaling for resilience.\nDesigned and validated inter-VPC connectivity using AWS Transit Gateway.\nImplemented storage and recovery procedures:\nEstablished backup plans and executed recovery tests. Deployed a static website on S3 and configured object access controls. Improved content delivery by integrating AWS CloudFront with S3.\nInitiated work on Machine Learning concepts (NLP):\nCovered supervised methods and sentiment analysis fundamentals. Conducted basic NLP preprocessing and exploratory model visualization. Formulated an initial concept for the final project. "
},
{
	"uri": "http://localhost:1313/InternshipReport/1-worklog/1.4-week4/",
	"title": "Week 4 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 4 Objectives: Master Hybrid Cloud workflows: Importing/Exporting Virtual Machines (VMs) and integrating On-premises storage. Deepen knowledge of AWS Storage (EFS, FSx, Storage Gateway) and Compute (Autoscaling, Lightsail). Build the mathematical foundation for Natural Language Processing (NLP): Vector Spaces, Probability, and Linear Algebra. Finalize the semester project concept and setup the documentation framework using Hugo. Tasks executed this week: Day Task Start Date End Date Resources Mon - Studied EC2 Auto Scaling, EFS/FSx, and Lightsail - Reinforced core storage and compute concepts - Reviewed probability basics and Bayes‚Äô theorem 29/09/2025 29/09/2025 https://www.youtube.com/@AWSStudyGroup/ https://www.coursera.org/learn/classification-vector-spaces-in-nlp/ Tue - Explored AWS database and security services - Practiced VM export/import workflows using VMware Workstation and AWS import tools 30/09/2025 30/09/2025 https://www.youtube.com/@AWSStudyGroup/ Wed - Practiced linear algebra in Python using NumPy - Implemented Euclidean distance and cosine similarity calculations - Explored word vector manipulation and Vector Space Model exercises 01/10/2025 01/10/2025 https://www.coursera.org/learn/classification-vector-spaces-in-nlp/ Thu - Imported virtual machines into AWS and instantiated instances from AMIs - Configured S3 ACLs and exported VM images as needed - Deployed an AWS Storage Gateway and mounted file shares on on-premises systems - Cleaned up temporary cloud resources 02/10/2025 02/10/2025 https://www.youtube.com/@AWSStudyGroup/ Fri - Reviewed Hugo themes and documentation best practices - Outlined the final workshop report structure - Held a wrap-up meeting to finalize the project idea and documentation plan 03/10/2025 03/10/2025 https://www.youtube.com/@AWSStudyGroup/ Week 4 Achievements: Hybrid cloud procedures validated:\nExported VMs from VMware Workstation and uploaded images to AWS. Created AMIs and launched instances from those images. Demonstrated the ability to move instances between cloud and local environments. Advanced storage solutions configured:\nDeployed and tested an AWS Storage Gateway. Mounted cloud file shares on on-premises hosts. Managed S3 ACLs to ensure appropriate access controls. Mathematical groundwork for NLP established:\nUsed Python/NumPy for linear algebra computations. Implemented Euclidean distance and cosine similarity for text vectors. Reviewed Bayes‚Äô theorem and Vector Space Models. Documentation \u0026amp; project planning:\nChose and configured a Hugo theme for reporting. Finalized the project idea and documentation outline with the team. "
},
{
	"uri": "http://localhost:1313/InternshipReport/1-worklog/1.5-week5/",
	"title": "Week 5 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 5 Objectives: Master advanced NLP algorithms: Vector transformation, K-nearest neighbors (KNN), and Hash tables. Deep dive into the AWS Storage ecosystem: S3 advanced features, Glacier, Snow Family, and Backup strategies. Implement Security compliance and Automation: Security Hub, IAM Roles, and AWS Lambda. Finalize the detailed execution plan for the final semester project. Tasks completed this week: Day Task Start Date End Date Resources Mon - Studied word vector transformations - Implemented K-nearest neighbors (KNN) concepts - Reviewed hash tables and hashing techniques - Completed the Word Translation code lab 06/10/2025 06/10/2025 https://www.coursera.org/learn/classification-vector-spaces-in-nlp/ Tue - Explored AWS storage services including S3 access points, storage classes, static website hosting and CORS - Reviewed Glacier archival options, AWS Snow Family, Storage Gateway, and backup strategies 07/10/2025 07/10/2025 https://www.youtube.com/@AWSStudyGroup/ Wed - Executed Lab Module 05: + Enabled Security Hub and assessed compliance + Provisioned VPC, Security Group and EC2 instance + Tagged resources and created an IAM role for Lambda + Implemented a Lambda function, verified behavior, and cleaned up resources 08/10/2025 08/10/2025 https://www.youtube.com/@AWSStudyGroup/ Thu - Translated documentation content as needed - Continued lab exercises (Module 05-28 to 05-30) - Held planning meetings to refine the final project schedule 09/10/2025 09/10/2025 https://www.youtube.com/@AWSStudyGroup/ Fri - Completed lab modules 05-31 through 05-33 - Convened a team meeting to consolidate the final project plan - Conducted a weekly review to reinforce learned concepts 10/10/2025 10/10/2025 https://www.youtube.com/@AWSStudyGroup/ Week 5 Achievements: Key accomplishments: Advanced NLP techniques and vector arithmetic:\nImplemented KNN and explored hash-table based methods. Completed a Word Translation lab leveraging vector transformations. Advanced AWS storage capabilities:\nDeployed S3 static hosting with CORS and managed storage classes. Reviewed Glacier archival workflows and Snow Family migration options. Security and automation:\nEnabled AWS Security Hub and evaluated compliance scores. Built serverless automation with AWS Lambda and appropriate IAM roles. Applied tagging best practices for EC2 resource management. Project milestones:\nProgressed through the Module 05 lab series. Finalized the detailed execution roadmap for the final project. "
},
{
	"uri": "http://localhost:1313/InternshipReport/1-worklog/1.6-week6/",
	"title": "Week 6 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 6 Objectives: Master AWS Security fundamentals: Shared Responsibility Model, Identity Center, and Key Management. Develop skills in designing and visualizing Cloud Architecture using professional standards (Draw.io). Deep dive into NLP Attention Models: Seq2seq, Neural Machine Translation (NMT), and Evaluation metrics. Collaborate with the team to draft and refine the High-Level Architecture for the final project. Tasks executed this week: Day Task Start Date End Date Resources Mon - Practiced creating AWS architecture diagrams using Draw.io with AWS icon sets - Completed Lab modules 05-44 and 05-48 13/10/2025 13/10/2025 https://www.youtube.com/@AWSStudyGroup/ Tue - Studied the Shared Responsibility Model and AWS identity services: IAM, Cognito, Organizations, and Identity Center - Reviewed KMS and Security Hub; supplemented learning with hands-on practice 14/10/2025 14/10/2025 https://www.youtube.com/@AWSStudyGroup/ Wed - Conducted a design meeting to produce a high-level architecture diagram - Studied Seq2Seq architectures and attention mechanisms (queries, keys, values) - Reviewed NMT concepts and evaluation metrics (BLEU, ROUGE-N) and decoding techniques such as Beam Search and Minimum Bayes Risk 15/10/2025 15/10/2025 https://www.coursera.org/learn/attention-models-in-nlp/ Thu - Refined AWS architecture diagramming skills and iteratively edited diagrams based on feedback 16/10/2025 16/10/2025 https://www.youtube.com/@AWSStudyGroup/ Fri - Reviewed and consolidated weekly knowledge - Iterated on the architecture diagram incorporating mentor feedback - Held a team discussion to agree on the diagram\u0026rsquo;s final structure 17/10/2025 17/10/2025 https://www.youtube.com/@AWSStudyGroup/ Week 6 Achievements: Security and identity:\nClarified the Shared Responsibility Model. Configured IAM and AWS Identity Center for administrative tasks. Investigated Cognito for application authentication and evaluated KMS for key management. Architecture design:\nBecame proficient with Draw.io and AWS iconography. Drafted and iterated on the project\u0026rsquo;s high-level architecture diagram. Incorporated mentor feedback into subsequent revisions. Advanced NLP topics:\nStudied Seq2Seq and attention mechanisms, focusing on queries, keys, and values. Reviewed model evaluation metrics (BLEU, ROUGE-N) and decoding strategies like Beam Search. Team coordination:\nAligned team members on architectural direction through focused design meetings. "
},
{
	"uri": "http://localhost:1313/InternshipReport/1-worklog/1.7-week7/",
	"title": "Week 7 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 7 Objectives: Master AWS Database services: RDS, Aurora, Redshift, and ElastiCache. Develop practical AI skills: Research and implement an AI Chatbot. Finalize the High-Level Architecture Diagram based on mentor feedback. Kick-start the Final Project implementation: Frontend and Backend design. Tasks completed this week: Day Task Start Date End Date Resources Mon - Completed Lab Module 06 and further iterated on the architecture diagram 20/10/2025 20/10/2025 https://www.youtube.com/@AWSStudyGroup/ Tue - Studied database concepts and AWS database offerings (RDS, Aurora, Redshift) - Reviewed caching with ElastiCache - Researched AI chatbot development approaches 21/10/2025 21/10/2025 https://www.youtube.com/@AWSStudyGroup/ Wed - Prototyped an AI chatbot and supplemented research on chatbot architectures - Incorporated mentor feedback into the system diagram 22/10/2025 22/10/2025 https://www.youtube.com/ Thu - Initiated the final project implementation and drafted front-end and back-end designs 23/10/2025 23/10/2025 Fri - Consolidated weekly learnings - Continued diagram revisions with peer feedback - Tested AI prototype and advanced the front-end/back-end designs 24/10/2025 24/10/2025 Week 7 Achievements: [Image of AWS RDS architecture]\nDatabase expertise:\nClarified distinctions between relational services (RDS, Aurora) and data warehousing (Redshift). Evaluated caching strategies using Amazon ElastiCache. AI prototyping:\nResearched and prototyped an AI chatbot integrated into the project scope. Architecture maturity:\nFinalized the system architecture after iterative reviews. Project kick-off:\nBegan development for the final project with initial front-end and back-end designs. "
},
{
	"uri": "http://localhost:1313/InternshipReport/1-worklog/1.8-week8/",
	"title": "Week 8 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 8 Objectives: Finalize the System Architecture and integrate the AI module into the main project. Complete the core development phase: Basic Frontend, Backend, and Project Proposal. Comprehensive review of all AWS modules and supplementary knowledge covered to date. Successfully complete the Midterm Exam. Tasks carried out this week: Day Task Start Date End Date Resources Mon - Revised the architecture diagram and refined service choices - Finalized the AI component and began integration with the application 27/10/2025 27/10/2025 Tue - Drafted the Project Proposal - Held team collaboration sessions - Implemented the basic front-end and back-end components 28/10/2025 28/10/2025 Wed - Conducted a thorough review of accumulated knowledge and supplemental materials 29/10/2025 29/10/2025 https://www.youtube.com/@AWSStudyGroup/ https://cloudjourney.awsstudygroup.com/ Thu - Continued knowledge consolidation and review of supplementary resources 30/10/2025 30/10/2025 https://www.youtube.com/@AWSStudyGroup/ https://cloudjourney.awsstudygroup.com/ Fri - Took the Midterm Exam - Held a meeting to adjust and prioritize project features 31/10/2025 31/10/2025 Week 8 Achievements: [Image of full stack development workflow]\nSystem integration and optimization:\nIntegrated the AI chatbot into the main application stack. Refined the AWS architecture to better match implementation constraints. Development progress:\nImplemented core front-end and back-end components. Completed and documented the Project Proposal. Knowledge consolidation and evaluation:\nReviewed core AWS modules and supplementary materials. Successfully completed the Midterm Exam. Iterative improvements:\nPrioritized and adjusted features following team discussions and test feedback. "
},
{
	"uri": "http://localhost:1313/InternshipReport/1-worklog/1.9-week9/",
	"title": "Week 9 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 9 Objectives: Deep dive into modern NLP architectures: Transformers, Attention Mechanisms, and Decoders. Explore Transfer Learning and Large Language Models (LLMs) like BERT, GPT, and T5. Implement Generative AI solutions using AWS Bedrock. Optimize the Final Project architecture and refine the Chatbot\u0026rsquo;s performance/UI. Tasks performed this week: Day Task Start Date End Date Resources Mon - Studied differences between Transformers and RNNs - Reviewed scaled dot-product attention and masked self-attention - Analyzed transformer decoders 03/11/2025 03/11/2025 https://www.coursera.org/learn/attention-models-in-nlp/ Tue - Completed a Transformer summarization lab - Optimized the chatbot logic and refined the user interface 04/11/2025 04/11/2025 https://www.coursera.org/learn/attention-models-in-nlp/ Wed - Held a meeting to optimize the AWS service selection - Studied transfer learning techniques and surveyed major LLMs (ELMo, GPT, BERT, T5) 05/11/2025 05/11/2025 https://www.coursera.org/learn/attention-models-in-nlp/ Thu - Explored AWS Bedrock and experimented with integrating it into the AI chatbot 06/11/2025 06/11/2025 Fri - Prepared and curated training/response data for the Bedrock-backed chatbot - Performed testing and resolved data-processing issues 07/11/2025 07/11/2025 Week 9 Achievements: Advanced NLP architectures:\nDistinguished Transformers from RNN architectures and examined attention variants. Implemented a Transformer-based summarizer in practical labs. Large language model exposure:\nStudied transfer learning paradigms and surveyed prominent LLMs (ELMo, GPT, BERT, T5). Generative AI on AWS:\nIntegrated AWS Bedrock features to enhance the chatbot\u0026rsquo;s generative capabilities. Curated and preprocessed context data and debugged integration issues. Product refinement:\nImproved chatbot UI and optimized the chosen AWS service stack for the final deployment. "
},
{
	"uri": "http://localhost:1313/InternshipReport/1-worklog/",
	"title": "Worklog",
	"tags": [],
	"description": "",
	"content": "The internship roadmap was divided into three main phases:\nFoundational Knowledge: Mastering AWS core services (Networking, Compute, Storage, Security) and Math for ML. Advanced Research: Deep diving into NLP, Transformers, and Generative AI (AWS Bedrock). Project Implementation: System architecture design, Full-stack development, and Serverless deployment. Below is the weekly breakdown of tasks and achievements:\nWeek 1: Introduction to Cloud Computing \u0026amp; AWS Account Setup\nWeek 2: Deep Dive into AWS Networking: VPC \u0026amp; Security\nWeek 3: Compute, Connectivity (Transit Gateway) \u0026amp; Intro to NLP\nWeek 4: Hybrid Cloud Solutions, Storage Gateway \u0026amp; Math for NLP\nWeek 5: Advanced Storage, Security Automation \u0026amp; NLP Algorithms\nWeek 6: Cloud Architecture Design, Identity Security \u0026amp; Attention Models\nWeek 7: Databases, AI Chatbot Prototyping \u0026amp; Project Kick-off\nWeek 8: System Integration, Midterm Exam \u0026amp; Project Proposal\nWeek 9: Transformers, LLMs \u0026amp; Generative AI with AWS Bedrock\nWeek 10: BERT Fine-tuning, Serverless Optimization \u0026amp; UI Completion\nWeek 11: Documentation, Final Deployment \u0026amp; Architectural Synchronization\nWeek 12: Final Review, Bug Fixing \u0026amp; Product Demo\nThis section provides a concise weekly log of activities, objectives, and accomplishments throughout the internship. Each week contains a list of planned tasks, references used, and the key outcomes achieved.\n"
},
{
	"uri": "http://localhost:1313/InternshipReport/5-workshop/5.4-databaseandstorage/5.4.2-create-s3/",
	"title": "Create an AWS S3",
	"tags": [],
	"description": "",
	"content": "In this section you will create S3 bucket to storage photos\nOpen the Amazon S3 Click Create bucket In create console, fill in name of bucket Then leave everything as default like picture Click Create bucket bottom "
},
{
	"uri": "http://localhost:1313/InternshipReport/5-workshop/5.3-vpc/5.3.3-create-security-groups/",
	"title": "Create Security Groups",
	"tags": [],
	"description": "",
	"content": " Open the Amazon VPC console Choose Security Groups -\u0026gt; click Create security group In Create Security group Spacific name of Security group Choose VPC created Add rule Inbound and Outbound for Security Group In ReGenZet project we have 4 Security groups, which are fargate-sg, rds-sg, alb-sg and endpoint-sg. fargate-sg is security group for AWS ECS Fargate Do again step 1 -\u0026gt; 3 Choose fargate-sg created Inbount Add rule security group of Application Load Balancer (ALB) is alb-sg Outbound Add rule security group of MySQl (rds-sg) and HTTPS Click Create security group rds-sg is security group for AWS RDS Do again step 1 -\u0026gt; 3 Choose rds-sg created Inbound Add rule security group of MySQL like this instruct Outbound is not Add rule Click Create security group alb-sg is security group for AWS Application Load Balancer (ALB) Do again step 1 -\u0026gt; 3 Inbound Add rule HTTPS and HTTP type like this instruct Outbound Add rule security group of AWS ECS Fargate (fargate-sg) Click Create security group endpoint-sg is security group for VPC Endpoints Do again step 1 -\u0026gt; 3 Inbound Add rule security group of AWS ECS Fargate (fargate-sg) Outbound is not Add rule "
},
{
	"uri": "http://localhost:1313/InternshipReport/5-workshop/5.3-vpc/5.3.2-create-subnets/",
	"title": "Create Subnets",
	"tags": [],
	"description": "",
	"content": "Create Public Subnet Open the Amazon VPC console Choose Subnets -\u0026gt; click Create subnet In Create subnet console: Choose VPC created Fill subnet name Choose AZ Spacific IPv4 subnet Then click Create subnet Create Private Subnet Do again step 1 -\u0026gt; 4 Click this Subnet -\u0026gt; Choose Route table Choose Route table ID is private Click Save "
},
{
	"uri": "http://localhost:1313/InternshipReport/5-workshop/5.3-vpc/5.3.4-create-vpc-endpoints/",
	"title": "Create VPC Endpoints",
	"tags": [],
	"description": "",
	"content": " Open the Amazon VPC console Choose Endpoints -\u0026gt; click Create endpoints In Create console: Fill name of VPC endpoint Type is AWS Services Search In this project we have 5 VPC Endpoints VPC Enpoint S3 Gateway (apexev-s3-gateway) In search box -\u0026gt; com.amazonaws.ap-southeast-1.s3 Choose type Gateway Choose VPC created Choose Route table private Policy is Full access Click Create endpoint VPC Enpoint ECR API \u0026amp; DKR Interface In search box -\u0026gt; ecr Will see ecr.api and ecr.dkr interface Do this twice and choose a different one each time Choose VPC created Tick two subnet private in two difference AZ Choose endpoint-sg Click Create endpoint VPC Enpoint Logs In search box -\u0026gt; com.amazonaws.ap-southeast-1.logs Choose com.amazonaws.ap-southeast-1.logs Choose VPC created Tick two subnet private in two difference AZ Choose endpoint-sg Click Create endpoint VPC Enpoint AWS SNS In search box -\u0026gt; com.amazonaws.ap-southeast-1.sns Choose com.amazonaws.ap-southeast-1.sns Choose VPC created Tick two subnet private in two difference AZ Choose endpoint-sg Click Create endpoint "
},
{
	"uri": "http://localhost:1313/InternshipReport/5-workshop/5.2-project-architecture/",
	"title": "Project Architecture",
	"tags": [],
	"description": "",
	"content": "Architecture Overview This document describes the recommended production-ready architecture for ReGenZet ‚Äî an EV Garage Management System ‚Äî and explains the technology choices used in the workshop.\nFrontend: A React single-page application deployed and hosted via AWS Amplify. Amplify provides automated CI/CD, asset hosting and integration with CloudFront for global caching and fast client delivery. Backend: Containerized Spring Boot services packaged as Docker images and deployed to Amazon ECS (Fargate). Fargate removes host management overhead and provides scalable, serverless compute for microservices. Database: Amazon RDS (MySQL/Postgres) hosted in private subnets. RDS provides automated backups, snapshots, Multi-AZ options and encryption at rest (KMS). API Management: Amazon API Gateway exposes a single HTTPS entry point for client traffic, handles request routing, TLS termination and request throttling. Media Storage: Amazon S3 holds vehicle inspection images, videos and other media. Use presigned URLs for secure direct-upload/download to offload traffic from the backend. Asynchronous / Serverless components: Email pipeline: Backend (Spring) publishes an event to SNS, which triggers a Lambda to send email via Amazon SES. AI/Chat pipeline: Frontend ‚Üí API Gateway ‚Üí Lambda ‚Üí Amazon Bedrock (or other managed LLM) for inference and conversational workflows. Network \u0026amp; Security: Deploy resources inside a VPC with well-defined Public and Private subnets. Use Security Groups and NACLs to control traffic. Use VPC Endpoints (Gateway and Interface) for S3 and private service access, keeping traffic inside the AWS network. Why this architecture? Security-first\nThe backend and RDS instances reside in private subnets and never expose database ports to the public internet. API Gateway and load-balanced frontends terminate TLS at the edge, while internal services communicate over private networking. Cost-efficiency\nFargate and Lambda offer a pay-for-what-you-use model. When appropriate, consider Fargate Spot for non-critical workloads and configure autoscaling and lifecycle policies for S3 to reduce costs. Operational simplicity \u0026amp; modern patterns\nClear separation of concerns between frontend and backend, with API Gateway as a single ingress point. Event-driven components (SNS, Lambda) decouple email and AI processing from request-response paths, improving resilience and scalability. Developer productivity\nAWS Amplify simplifies frontend CI/CD and hosting. Container workflows with Docker + ECR and ECS Fargate enable reproducible deployments for backend services. Security and best-practice highlights\nLeast-privilege IAM roles for services and cross-account access where needed. KMS-managed encryption for RDS and S3 objects. WAF and rate-limiting on API Gateway to mitigate application-level attacks. This architecture balances enterprise-grade security with cost-effective serverless patterns and provides a pragmatic path for incremental adoption of advanced features (observability, multi-region DR, Bedrock-powered AI).\n"
},
{
	"uri": "http://localhost:1313/InternshipReport/2-proposal/",
	"title": "Proposal",
	"tags": [],
	"description": "",
	"content": "APEX-EV Electric Vehicle Service Platform 1. Executive Summary RenGen is a comprehensive management platform designed to digitize and optimize maintenance workflows at service centers. The system centrally manages the entire service lifecycle‚Äîfrom request intake and repair processing to customer care‚Äîhelping to eliminate manual tasks and enhance efficiency. Leveraging the power of the AWS cloud, RenGen combines flexible container architecture on Amazon ECS Fargate with the intelligent processing capabilities of Generative AI through Amazon Bedrock. The solution integrates automated development processes (CI/CD) from GitLab, ensuring rapid deployment speeds, high security, and rigorous monitoring, delivering a superior experience for end-users.\n2. Problem Statement What‚Äôs the Problem? Current operational processes rely heavily on manual methods, leading to inefficiencies, fragmented data, and a lack of intelligent support tools for automated customer interaction.\nThe Solution The platform employs a modern architecture, starting at the Edge layer with Amazon Route 53 for user routing. The interface (Frontend) is hosted on AWS Amplify Hosting, ensuring fast and stable access. Amazon API Gateway acts as the central hub, intelligently routing requests.\nTo ensure security, critical components such as ECS Fargate and the Amazon RDS database are placed in a Private Subnet, completely isolated from the public internet. Image data is stored on Amazon S3 and accessed securely via S3 Endpoints. Additionally, the software development process is fully automated: source code from GitLab is packaged and pushed to Amazon ECR for deployment to ECS.\nBenefits and Return on Investment Adopting this architecture delivers a significant competitive advantage by integrating Artificial Intelligence (GenAI) via Amazon Bedrock, which helps automate customer care and data analysis. The system ensures high availability and data security thanks to the VPC network separation design (Public/Private subnets).\nThe CI/CD process integrated with GitLab and ECR helps minimize downtime when updating new features, while Amazon CloudWatch provides comprehensive monitoring to detect incidents instantly. The cost model is optimized thanks to the use of Fargate (Serverless container) and Lambda (Pay-per-use), ensuring businesses only pay for the actual resources used. This investment not only resolves current operational challenges but also creates a solid technological foundation for long-term growth, with the expected Return on Investment (ROI) period significantly shortened.\n3. Solution Architecture The RenGen management platform utilizes a modern architecture deployed on AWS (Region ap-southeast-2), initiated by user access via Amazon Route 53 at the Edge layer. The User Interface (Frontend) is hosted on AWS Amplify Hosting, which establishes a direct connection to Amazon API Gateway as the central entry point.\nFrom the API Gateway, the data flow is strategically divided into three distinct paths:\nAI Tasks: Requests are routed to AWS Lambda to interact with Amazon Bedrock for generative AI capabilities. Notification Tasks: Asynchronous requests trigger AWS Lambda to handle email communications via Amazon SES. Core Business Logic: Traffic is directed through an Application Load Balancer (ALB) located in the Public Subnet, then forwarded to Amazon ECS Fargate instances secured within a Private Subnet. Data \u0026amp; Security:\nRelational data is persistently stored in Amazon RDS within the Private Subnet. To optimize security and performance, the architecture utilizes VPC Endpoints to keep traffic strictly within the AWS internal network:\nStatic assets and images stored in Amazon S3 are accessed securely via S3 Endpoints. Container images are pulled directly from Amazon ECR via ECR Endpoints. By leveraging these endpoints, the system eliminates the need for a NAT Gateway, thereby reducing costs and minimizing public internet exposure.\nDevOps \u0026amp; Monitoring:\nGitLab is used for source code management and CI/CD, automatically pushing deployments to Amplify (Frontend) and container images to ECR (Backend). AWS Services Used Route 53: DNS service, responsible for routing the domain (Edge layer) to the application. AWS Amplify Hosting: Hosts the web interface (frontend) and can integrate with CDN/WAF. In the diagram, it receives traffic from Route 53. Amazon API Gateway: The main entry point (Gateway), receiving and routing all requests from the frontend/Amplify to processing services. AWS Lambda (Bedrock): Handles AI/Generative AI tasks (prediction/content generation) by communicating with Amazon Bedrock. AWS Lambda (SES): Handles asynchronous tasks, such as processing notifications to send emails via AWS SES. Amazon Bedrock: General AI service (Gen AI), providing foundation models to execute intelligent business operations. AWS SES: Email sending service, performs the sending of notifications, quotes, or processing results from Lambda. VPC: Virtual network environment containing and protecting AWS resources (like ALB, ECS Fargate, RDS). ALB (Application Load Balancer): Load balancer, distributing traffic from API Gateway to application containers running on ECS Fargate. Amazon ECS Fargate: Runs the backend application as containers without server management, handling core business logic. Amazon RDS: Provides a relational database, placed in a Private Subnet to store structured data. Amazon S3: Stores multimedia files like photos or other large data. ECR: Repository for application container images (Docker), used by ECS Fargate for deployment. AWS CloudWatch: Monitoring service, collecting logs and metrics from the entire system to track performance and detect issues. Component Design Request Handling: Amazon Route 53 routes user domain requests to AWS Amplify Hosting, where the frontend interface is hosted. From there, API requests are forwarded to Amazon API Gateway, which acts as the central entry point to receive and route all incoming traffic.\nBusiness Logic Processing:\nCore Logic: All primary business operations are handled by containerized applications running on Amazon ECS Fargate, deployed within a Private Subnet to ensure maximum security. AI \u0026amp; Asynchronous Tasks: Generative AI tasks are processed by AWS Lambda interacting with Amazon Bedrock. Auxiliary tasks, such as email notifications, are handled by separate AWS Lambda functions triggering Amazon SES. Network Infrastructure:\nPublic Subnet: Hosts the Application Load Balancer (ALB) to receive and distribute external traffic. Private Subnet: Dedicated to sensitive resources including ECS Fargate and Amazon RDS, ensuring they are isolated from direct public internet access. VPC Endpoints: The system explicitly utilizes S3 Endpoints and ECR Endpoints. This design allows ECS Fargate to pull container images and access file storage securely within the AWS internal network, without traversing the public internet. Data Storage:\nAmazon RDS: Stores sensitive, structured relational data. Amazon S3: Stores multimedia files and large datasets. Deployment and Monitoring: The deployment pipeline is managed via GitLab, which triggers updates to AWS Amplify (Frontend) and pushes Docker images to Amazon ECR (Backend). Amazon CloudWatch provides comprehensive monitoring of performance logs and metrics across all services, from ECS and Lambda to RDS.\n4. Technical Implementation Implementation Phases The development project for the RenGen Smart Electric Vehicle Maintenance Platform ‚Äî including the integration of an AI virtual assistant and a service management system ‚Äî undergoes 4 phases:\nResearch and Architectural Design: Research suitable technologies (React.js, Spring Boot, AWS Bedrock) and design a system architecture combining Containers (ECS) and Serverless (Lambda) on AWS (1 month prior to commencement). Cost Estimation and Feasibility Check: Use the AWS Pricing Calculator to estimate operating costs for core services such as ECS Fargate, RDS, and token costs for Amazon Bedrock, and propose the most feasible solution. Architecture Adjustment for Cost/Solution Optimization: Refine the architecture, select appropriate configurations for ECS Fargate and RDS, and optimize Lambda runtime (timeouts) to balance AI processing performance and cost. Development, Testing, and Deployment: Program the React.js application (Frontend) and Spring Boot (Backend), integrate the Bedrock Agent, deploy CI/CD pipelines via GitLab, package Docker images to ECR, and launch operations on ECS. Technical Requirements Technical Requirements User Interface (Frontend): Practical knowledge of React.js to build scheduling interfaces and chat with the AI virtual assistant. Use AWS Amplify to automate the deployment process (Hosting), connect with Amazon API Gateway to send secure processing requests, ensuring a smooth user experience on all devices. Core System (Backend \u0026amp; Infrastructure): In-depth knowledge of Java/Spring Boot to develop maintenance business logic. The application is packaged using Docker, with images stored on AWS ECR and running on Amazon ECS Fargate. Requires understanding of Amazon RDS for relational databases (storing vehicle profiles, maintenance history). Specifically, requires AWS Lambda (Python) programming skills to connect with Amazon Bedrock (AI/Chatbot processing) and AWS SES (sending asynchronous email notifications). Manage detailed user authentication and authorization (customers/technicians) via Amazon Cognito. 5. Timeline \u0026amp; Milestones Project Timeline\nPhase 1 (Week 1-2): Design and Foundation:: Analyze \u0026amp; Design detailed AWS architecture (VPC, Subnets, Security Groups). Design Database (RDS Schema) and define APIs (Swagger/OpenAPI). Configure infrastructure environment: Setup VPC (Public/Private Subnets), IAM Roles, and Amazon Cognito (User Pools). Setup CI/CD: Configure Pipeline on GitLab to automatically build Docker Images, push to Amazon ECR, and deploy Frontend to AWS Amplify. Phase 2 (Week 3-4): Core Service Flow Development:: Develop Customer flow (Frontend/Backend): Registration/Login, Vehicle Profile Management, Appointment Scheduling (stored in RDS). Develop Service Advisor flow: Vehicle Reception, Create Quotations and Repair Orders. Ph√°t tri·ªÉn lu·ªìng K·ªπ thu·∫≠t vi√™n: Xem danh s√°ch vi·ªác c·∫ßn l√†m (Task list), C·∫≠p nh·∫≠t ti·∫øn ƒë·ªô b·∫£o d∆∞·ª°ng v√† t·∫£i ·∫£nh/video l√™n Amazon S3. Phase 3 (Week 5-6): Administration \u0026amp; Advanced Feature Development:: Build Administration Module: Report Dashboard, Spare Parts Management (Inventory), and Personnel Management.Build Administration Module: Report Dashboard, Spare Parts Management (Inventory), and Personnel Management. Write AWS Lambda to connect Amazon Bedrock Agent (AI Chatbot for customer support) and expose via API Gateway. Write AWS Lambda to trigger AWS SES for sending automatic notification emails/quotations to customers. Configure NAT Gateway so resources in Private Subnet (Lambda, ECS) can securely connect to the Internet/AWS Services. Phase 4 (Week 7-8): Testing, Optimization, and Operation:: Internal User Acceptance Testing (UAT) to ensure the flow from Web -\u0026gt; API Gateway -\u0026gt; Lambda/ECS -\u0026gt; DB operates smoothly. Optimize security: Configure AWS WAF (block SQL Injection, XSS) and review IAM access rights. Operational monitoring: Setup Dashboard on Amazon CloudWatch to track logs and metrics of ECS Fargate and Lambda. Official deployment. 6. Budget Estimation Infrastructure Costs\nAmazon ECS Fargate: ~11.00 USD/month. Application Load Balancer (ALB): ~16.43 USD/month. Amazon Bedrock (AI): ~5.00 USD/month (Calculated by Token count). AWS Lambda: 0.00 USD/month (Free Tier). Amazon RDS \u0026amp; ElastiCache: 0.00 USD/month (Free Tier). S3 Standard: ~0.15 USD/month. AWS Amplify \u0026amp; API Gateway: ~0.50 USD/month. Amazon CloudWatch: 0.00 USD/month (Free Tier). Amazon SES: 0.00 USD/month (Free Tier). Total: ~32.63/month.\n7. Risk Assessment Risk Matrix System downtime: High impact, low probability. Security breach/Data loss: Very high impact, low probability. Operational cost overrun: Medium impact, medium probability. Mitigation Strategies System: Deploy infrastructure across Multi-AZ for RDS and ECS Fargate. Use Application Load Balancer for automatic load distribution and recovery. Security: Use AWS WAF to filter malicious requests. Strict authorization with Amazon Cognito and apply least privilege principle. Backend placed in a separate network (Private Subnet). Cost: Use AWS Budgets to set alerts when costs exceed thresholds. Regularly monitor and optimize resources (right-sizing) to avoid waste. Incorrect AI response: Medium impact, medium probability. Contingency Plans System: Deploy ECS Fargate and RDS infrastructure across Multi-AZ to ensure high availability. Use Application Load Balancer for automatic load coordination and Auto-scaling to expand Tasks when traffic spikes. AI Quality: Limit Bedrock Agent response scope via strict Prompt Engineering (System Prompts) and only allow information retrieval from moderated Knowledge Bases. Enable Automated Backups for RDS and Point-in-time Recovery to restore data to any point in time. 8. Expected Outcomes Technical Improvements: Technical Improvements: Successfully build a modern Hybrid Architecture combining Microservices (ECS Fargate) and Serverless (Lambda, Bedrock), ensuring flexible scalability without managing physical servers.\nLong-term Value Enhance customer experience: AI virtual assistant operating 24/7 helps reduce waiting time, increasing appointment conversion rates and car owner satisfaction.\nData assets: Maintenance history and interaction behavior data are centrally stored on RDS/S3, creating a premise for deploying AI Predictive Maintenance models for electric vehicle batteries and motors in the future.\n"
},
{
	"uri": "http://localhost:1313/InternshipReport/1-worklog/1.10-week10/",
	"title": "Week 10 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 10 Objectives: Master advanced NLP techniques: BERT architecture, Fine-tuning, and Multi-Task Training strategies. Finalize the product interface (UI) and conduct comprehensive system testing. Optimize system architecture by shifting AI integration to a Serverless model. Implement direct Frontend-to-Bedrock integration using AWS Lambda. Tasks executed this week: Day Task Start Date End Date Resources Mon - Studied the BERT architecture and fine-tuning techniques - Reviewed multi-task training strategies - Completed a fine-tuning lab using available datasets 10/11/2025 10/11/2025 https://www.coursera.org/learn/attention-models-in-nlp/ Tue - Finalized the user interface and verified core features - Conducted product-level testing 11/11/2025 11/11/2025 Wed - Held feature review meeting and prioritized enhancements - Performed system optimization tasks 12/11/2025 12/11/2025 Thu - Continued system optimization and resolved integration issues affecting the Bedrock-powered chatbot 13/11/2025 13/11/2025 https://cloudjourney.awsstudygroup.com/ Fri - Implemented an AWS Lambda function to enable Frontend-to-Bedrock interaction - Investigated front-end integration patterns for Bedrock 14/11/2025 14/11/2025 https://cloudjourney.awsstudygroup.com/ Week 10 Achievements: Advanced NLP (BERT):\nReviewed BERT internals and completed fine-tuning experiments. Applied multi-task training principles where appropriate. Product completion:\nFinalized the UI and validated core features through testing. Architectural improvements:\nMigrated the chatbot integration toward a serverless model. Implemented Lambda-based Frontend-to-Bedrock calls to reduce latency and improve scalability. Tuned system performance according to test results and feedback. "
},
{
	"uri": "http://localhost:1313/InternshipReport/1-worklog/1.11-week11/",
	"title": "Week 11 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 11 Objectives: Complete and formalize all project documentation (Internship Report, Proposal, and Workshop materials). Synchronize the technical architecture diagram with the actual implemented solution. Finalize the integration of all AWS services. Execute the final deployment of the project to the AWS Cloud and perform post-deployment testing. Tasks completed this week: Day Task Start Date End Date Resources Mon - Continued drafting the Internship Report and performed targeted system optimizations 17/11/2025 17/11/2025 Tue - Updated the architecture diagram to reflect recent changes - Revised the Project Proposal and Workshop materials - Convened a team meeting to align on completion tasks 18/11/2025 18/11/2025 Wed - Finalized project deliverables and completed remaining edits 19/11/2025 19/11/2025 Thu - Performed final AWS service integration and end-to-end validation 20/11/2025 20/11/2025 https://cloudjourney.awsstudygroup.com/ Fri - Conducted post-deployment verification and fixed any remaining issues 21/11/2025 21/11/2025 Week 11 Achievements: Documentation:\nCompleted and polished the Internship Report. Updated the Project Proposal and Workshop materials to match the final implementation. Architecture alignment:\nSynchronized the architecture diagram with the deployed solution. Obtained team sign-off on the final design. Deployment and validation:\nIntegrated core AWS services (Bedrock, Lambda, databases) into the system. Deployed the final application to AWS and performed thorough post-deployment testing and remediation. "
},
{
	"uri": "http://localhost:1313/InternshipReport/1-worklog/1.12-week12/",
	"title": "Week 12 Worklog",
	"tags": [],
	"description": "",
	"content": "Week 12 Objectives: Complete and polish the Internship Report. Identify, debug, and resolve all remaining issues found during the deployment phase. Implement final system optimizations based on team consensus. Conduct a final internal review and user experience session for the semester project. Tasks executed this week: Day Task Start Date End Date Resources Mon - Continued writing the Internship Report and addressed deployment-related defects 24/11/2025 24/11/2025 Tue - Performed targeted optimizations and convened a team session to triage and resolve identified issues 25/11/2025 25/11/2025 Wed - Implemented the agreed technical fixes and validated the system accordingly 26/11/2025 26/11/2025 Thu - Continued validation and hardening of the system following group recommendations 27/11/2025 27/11/2025 Fri - Finalized the project and conducted an internal demo and user experience session with the team 28/11/2025 28/11/2025 Week 12 Achievements: Documentation and reporting:\nFinalized and edited the Internship Report for submission. Quality assurance \u0026amp; remediation:\nIdentified and prioritized deployment defects. Implemented corrective actions in collaboration with the team. System stabilization:\nApplied agreed fixes and validated system stability and performance. Final delivery:\nConducted the end-of-semester demo and user experience session; all core features validated for submission. "
},
{
	"uri": "http://localhost:1313/InternshipReport/5-workshop/5.4-databaseandstorage/5.4.3-create-ecr/",
	"title": "Create AWS ECR",
	"tags": [],
	"description": "",
	"content": " Open the Amazon Elastic Container Registry In create console, fill in repository name Choose Mutable in Image tag mutability Then click Create "
},
{
	"uri": "http://localhost:1313/InternshipReport/3-blogstranslated/",
	"title": "Translated Blogs",
	"tags": [],
	"description": "",
	"content": "Blog 1 - How BeyondTrust embedded Amazon QuickSight for identity security insights BeyondTrust leveraged Amazon QuickSight to build faster, more scalable, and cost-efficient identity security analytics. QuickSight enabled rapid dashboard development, seamless embedding, multi-tenant security, and a streamlined CI/CD pipeline that reduced deployment time from weeks to days and cut operational costs by 60%. With a custom UI and automated workflows, BeyondTrust improved reporting efficiency and customer value. They plan to expand QuickSight with Amazon Q, enhanced editor features, pixel-perfect reports, and multi-region deployments to further strengthen their analytics capabilities.\nBlog 2 - How to securely deliver business intelligence to internal-facing applications with Amazon QuickSight This article explains how to securely integrate Amazon QuickSight into internal applications by leveraging a company‚Äôs centralized access management via IAM Identity Center. It covers three access models: direct dashboard access, embedding in an internal website, and embedding in a restricted SPA. The most advanced approach uses user JWTs along with API Gateway and Lambda to generate dynamic QuickSight embed URLs, enabling seamless, pop-up-free embedded dashboards while enforcing proper authorization. This architecture allows organizations to safely deliver rich business intelligence experiences within existing identity and access control frameworks.\nBlog 3 - Software developer career paths: 2025 job guide This article provides a comprehensive guide to 17 software development career paths for 2025, ranging from foundational roles (Front-end, Back-end, Full-stack) to specialized fields (AI/ML, Cloud, DevOps, Security). Each path details average salaries, required technical skills, and portfolio ideas, ultimately emphasizing that career success is like a \u0026ldquo;menu\u0026rdquo;‚Äîa personal choice based on your individual goals and preferences.\n"
},
{
	"uri": "http://localhost:1313/InternshipReport/5-workshop/5.3-vpc/",
	"title": "VPC",
	"tags": [],
	"description": "",
	"content": "Intro VPC (Virtual Private Cloud) is a logically isolated virtual private network space in AWS Cloud. It acts as your personal data center in the cloud, giving you complete control over the network environment.\nCore components: Route Table Subnets Internet Gateway Security Groups Create VPC Open the Amazon VPC console Choose Your VPCs, then click Create VPC In the create VPC console: Specify name of the Name tag: my-vpc-01 IPv4 CIDR : 10.0.0.0/16 Then click Create VPC Content Create Route Table \u0026amp; Internet Gateway Create Subnets Create Security Groups Create VPC Endpoints "
},
{
	"uri": "http://localhost:1313/InternshipReport/4-eventparticipated/",
	"title": "Attended Events",
	"tags": [],
	"description": "",
	"content": "During my internship, I participated in 3 events. Each event was a memorable experience filled with new, interesting, and useful knowledge, along with gifts and wonderful moments.\nEvent 1 Event Name: AWS Well-Architected Security Pillar\nTime: 09:00, November 29, 2025\nLocation: Level 26, Bitexco Financial Tower, No. 02 Hai Trieu Street, Ben Nghe Ward, District 1, Ho Chi Minh City\nRole: Attendee\nEvent 2 Event Name: DevOps on AWS\nTime: 09:00, November 17, 2025\nLocation: Level 26, Bitexco Financial Tower, No. 02 Hai Trieu Street, Ben Nghe Ward, District 1, Ho Chi Minh City\nRole: Attendee\nEvent 3 Event Name: AWS AI/ML and Generative AI Workshop\nTime: 09:00, November 15, 2025\nLocation: Level 26, Bitexco Financial Tower, No. 02 Hai Trieu Street, Ben Nghe Ward, District 1, Ho Chi Minh City\nRole: Attendee\n"
},
{
	"uri": "http://localhost:1313/InternshipReport/5-workshop/5.4-databaseandstorage/",
	"title": "Database And Storage",
	"tags": [],
	"description": "",
	"content": "Overview This project used three data storage services which are: AWS RDS(Relational Database Service) is a AWS service to config database and is located in Private Subnet AWS S3 (Simple Storage Service) is a AWS service to storage picture and video AWS ECR (Elastic Container Registry) is a AWS service to storage docker image Content Create RDS Create S3 Create ECR "
},
{
	"uri": "http://localhost:1313/InternshipReport/5-workshop/5.5-computeandcontainer/",
	"title": "Compute And Container",
	"tags": [],
	"description": "",
	"content": "IAM Role Create ecsTaskExecutionRole role to AWS ECS (Elastic Container Service) pull docker image and write logs from ECR repository Open the Amazon IAM In left navbar, choose Roles, then click Create role In create console, choose AWS service and select Use case is EC2 then click Next In Add permissions step, search AmazonECSTaskExecutionRolePolicy and select this Policy, then click Next In Name, review, and create, fill in Role name is ecsTaskExecutionRole , then click Create role Create FargateTaskRole role to allow Fargate access resource In left navbar, choose Roles, then click Create role In create console, choose AWS service and select Use case is EC2 then click Next In Add permissions step, search AmazonS3FullAccess, AmazonSESFullAccess and AmazonSNSFullAccess, then click Next Review and fill in Role name is FargateTaskRole, then click Create role ECS Cluster Create ECS Cluster is place to Fargate running Open the Amazon ECS In left navbar, choose Clusters, then click Create Cluster In create console, fill in Cluster name In Infrastructure, select Fargate only Then click Create Task definitions Create Task definitions is a container design In left navbar of ECS console, choose Task definitions, then click **Create new task definitions In create console, fill in Task definition family Select AWS Fargate in Launch type of Infrastructure requirements Choose Task role is FargateTaskRole Choose Task execution role is ecsTaskExecutionRole In Container, fill in name and URL of ECR, then Add Environment variable Scroll down to the bottom and click Create ECS Service Create ECS Service to run Task definitions In left navbar, choose Clusters, then click Cluster created In tab Sevices, click Create In create console, choose Task definition family Choose Task definition revision Fill in Service name In Compute options choose Capacity provider strategy In Capacity provider, select FARGATE In Platform version, select LATEST In Deployment configuration, Scheduling strategy is Replica and Desired tasks is 1 Then click Create "
},
{
	"uri": "http://localhost:1313/InternshipReport/5-workshop/",
	"title": "Workshop",
	"tags": [],
	"description": "",
	"content": "Deploy ReGenZet Management System To AWS Overview ReGenZet is an enterprise-grade EV garage management platform. The objective of this workshop is to design and deploy a secure, cost-optimized, and highly automated cloud infrastructure on AWS to host ApexEV\u0026rsquo;s frontend, backend, storage, and serverless AI/ML functions.\nKey architectural principles:\nSecurity-first: least-privilege IAM, encrypted data at rest and in transit, network isolation and controlled service endpoints. Cost optimization: use managed services with pay-as-you-go models, right-sizing, and automated lifecycle policies for storage and compute. Automation \u0026amp; Observability: Infrastructure-as-Code, CI/CD pipelines, centralized logging, and automated monitoring/alarms. Core services used in this workshop:\nAWS ECS (Fargate) ‚Äî run backend microservices without managing servers. AWS Amplify ‚Äî host the frontend, provide CI/CD for web clients and manage hosting. Amazon RDS ‚Äî managed relational database for transactional data. Amazon S3 ‚Äî object storage for media, backups, and static assets. AWS Lambda ‚Äî serverless functions for AI/ML processing pipelines, notifications and background tasks. This workshop contains hands-on modules covering the end-to-end stack and best practices for each layer.\nContent Workshop Overview Project Architecture VPC Of Project Database And Storage Compute And Container Create Load Balancing Create Amplify And API Gateway Intruct Deploy Code Frontend and Backend "
},
{
	"uri": "http://localhost:1313/InternshipReport/6-self-evaluation/",
	"title": "Self-Assessment",
	"tags": [],
	"description": "",
	"content": "During my internship at [First Cloud Journey / AWS Study Group] from September 15, 2025 to November 28, 2025, I had the opportunity to bridge the gap between academic theory and professional application in the field of Cloud Computing and Artificial Intelligence.\nI actively participated in the \u0026ldquo;Development of an Intelligent AI Chatbot using AWS Bedrock and Serverless Architecture\u0026rdquo; project. Through this intensive period, I significantly improved my skills in Cloud Infrastructure (AWS VPC, EC2, Lambda), Natural Language Processing (BERT, Transformers), and Full-stack System Integration.\nIn terms of work ethic, I consistently strived to master new technologies (such as GenAI and Serverless), complied with project timelines, and collaborated effectively with mentors and team members to optimize the system architecture.\nTo objectively reflect on my internship period, I evaluate myself based on the following criteria:\nNo. Criteria Description Good Fair Average 1 Professional knowledge \u0026amp; skills Grasping AWS core services, NLP algorithms, and applying them to build a functional product. ‚úÖ ‚òê ‚òê 2 Ability to learn Rapidly adapting to new tech stacks (AWS Bedrock, Hugging Face) within a short timeframe. ‚úÖ ‚òê ‚òê 3 Proactiveness Proposing architectural changes (Migration to Serverless) to improve performance. ‚úÖ ‚òê ‚òê 4 Sense of responsibility Committing to deadlines for the Proposal, Midterm Exam, and Final Deployment. ‚úÖ ‚òê ‚òê 5 Discipline Adhering to strict schedules, reporting guidelines, and organizational rules. ‚òê ‚úÖ ‚òê 6 Progressive mindset Receptive to feedback regarding Architecture Diagrams and UI/UX design. ‚úÖ ‚òê ‚òê 7 Communication Articulating technical concepts clearly in weekly reports and team meetings. ‚òê ‚úÖ ‚òê 8 Teamwork Coordinating with Front-end and Back-end members to resolve integration conflicts. ‚úÖ ‚òê ‚òê 9 Professional conduct Maintaining a respectful and professional attitude towards mentors and peers. ‚úÖ ‚òê ‚òê 10 Problem-solving skills Debugging integration errors and optimizing system latency during the testing phase. ‚òê ‚úÖ ‚òê 11 Contribution to project/team Delivering a working AI module and finalizing the system deployment on AWS. ‚úÖ ‚òê ‚òê 12 Overall General evaluation of the entire internship period. ‚úÖ ‚òê ‚òê Areas for Improvement Enhance Operational Discipline: I need to strengthen my adherence to strict organizational workflows and time management to avoid last-minute crunches during deployment phases. Deepen Problem-Solving Strategy: Move from \u0026ldquo;reactive debugging\u0026rdquo; to \u0026ldquo;proactive architectural design\u0026rdquo; to anticipate and prevent system errors before they occur. "
},
{
	"uri": "http://localhost:1313/InternshipReport/5-workshop/5.7-amplifyandapigateway/",
	"title": "Create Amplify And API Gateway",
	"tags": [],
	"description": "",
	"content": "AWS Amplify Create Amplify to deploy Frontend Open the Amazon Amplify Click Create new app In create console, choose Gitlab, then click Next In step Add repository and branch, login with Gitlab, then choose Git Repository and branch need to deploy Then click Next Setting format with your type code in your Frontend, then click Next Review and click Save and deploy After this step wait about 3-5 minutes to deploy and you can access your app from internet API Gateway API Gateway is service to transfer HTTP and HTTPS between Amplify (Frontend) and Fargate (Backend) Open the Amazon API Gateway Click Create API Choose REST API and click Build In create console, choose API details is New API Fill in API name API endpoint type is Regional Security policy is SecurityPolicy_TLS13_1_2_2021_06 Then click Create API In left navbar, choose APIs and select API Gateway created In console API Gateway click Create Resource then fill in Resource name and click Create resource In console resource API Gateway, click Create method In Method details choose ANY, and Integration type is HTTP Proxy HTTP method select ANY, and Endpoint URL is Endpoints of ALB Then scroll down to the bottom and click Create method In resource proxy, create method In create console, choose Integration type is Mock and Method type is OPTIONS Then click Create method Now we finish setup API Gateway for project "
},
{
	"uri": "http://localhost:1313/InternshipReport/5-workshop/5.6-createalb/",
	"title": "Create AWS Load Balancers",
	"tags": [],
	"description": "",
	"content": " Open the Amazon EC2 In left navbar, choose Load Balancers, then click Create load balancer Choose Application Load Balancer In create console, fill in Load balancer name Scheme is Internet-facing, then select VPC In Availability Zones and subnets choose two AZ and select two subnet in public\\ Security groups select alb-sg Then scroll down to the bottom and click Create load balancer "
},
{
	"uri": "http://localhost:1313/InternshipReport/5-workshop/5.8-instruct-deploy-be-fe/",
	"title": "Instruct Deploy BackEnd And Frontend",
	"tags": [],
	"description": "",
	"content": "Deploy Frontend Instructure Deploy Frontend to Amplify Open terminal in your code from your compute Commit and Push to branch of Gitlab which define in Amplify Amplify auto CICD and deploy your Frontend Wait 3-5 minutes Deploy Backend Instructure Deploy Backend to Fargate Open the Amazon ECR In left navbar, choose Repository and select ECR repository created Open terminal in your code from your compute Write syntax \u0026ldquo;AWS configure\u0026rdquo; to setup access key and secret key of your AWS account After setup AWS account for CLI, comeback console of ECR Repository Click View push command, you will see syntax to push docker image to ECR repository Then copy and paste it to terminal of your Backend project Fisnish this step, AWS ECS Fargate will auto pull and run image have tag latest Finally,Congratulations for finish this workshop with deploy success project to AWS. "
},
{
	"uri": "http://localhost:1313/InternshipReport/7-feedback/",
	"title": "Sharing and Feedback",
	"tags": [],
	"description": "",
	"content": "Overall Evaluation 1. Working Environment\nThe working environment is very friendly and open. FCJ members are always willing to help whenever I encounter difficulties, even outside working hours. The workspace is tidy and comfortable, helping me focus better. However, I think it would be nice to have more social gatherings or team bonding activities to strengthen relationships.\n2. Support from Mentor / Team Admin\nThe mentor provides very detailed guidance, explains clearly when I don‚Äôt understand, and always encourages me to ask questions. The admin team supports administrative tasks, provides necessary documents, and creates favorable conditions for me to work effectively. I especially appreciate that the mentor allows me to try and solve problems myself instead of just giving the answer.\n3. Relevance of Work to Academic Major\nThe tasks I was assigned align well with the knowledge I learned at university, while also introducing me to new areas I had never encountered before. This allowed me to both strengthen my foundational knowledge and gain practical skills.\n4. Learning \u0026amp; Skill Development Opportunities\nDuring the internship, I learned many new skills such as using project management tools, teamwork skills, and professional communication in a corporate environment. The mentor also shared valuable real-world experiences that helped me better plan my career path.\n5. Company Culture \u0026amp; Team Spirit\nThe company culture is very positive: everyone respects each other, works seriously but still keeps things enjoyable. When there are urgent projects, everyone works together and supports one another regardless of their position. This made me feel like a real part of the team, even as an intern.\n6. Internship Policies / Benefits\nThe company provides an internship allowance and offers flexible working hours when needed. In addition, having the opportunity to join internal training sessions is a big plus.\nAdditional Questions What did you find most satisfying during your internship? What do you think the company should improve for future interns? If recommending to a friend, would you suggest they intern here? Why or why not? Suggestions \u0026amp; Expectations Do you have any suggestions to improve the internship experience? Would you like to continue this program in the future? Any other comments (free sharing): "
},
{
	"uri": "http://localhost:1313/InternshipReport/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/InternshipReport/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]